# Speech-Summarization
Speech summarization techniques take human speech as input and then output an abridged version as text or speech. It seeks to identify the most important content within human speech and then generate a condensed form.Speech summarization has applications in many domains from information technology to health care, for example improving speech archives or reducing clinical documentation burden.  Summarized speech should also be more understandable than a direct transcript of the speech, as it excludes the breaks and irregularities, as well as the repairs or repetitions that are common in speech. The steady improvement in automatic speech recognition accuracy, audio capture quality, and the increased popularity of natural language as a computer interface have underpinned the recent growth in interest for speech summarization methods. In healthcare, speech summarization has the potential to create a new generation of digital scribes (systems that generate clinical records from spoken speech) and conversational agents which can interact with patients. A speech summarization system takes speech as its input and generates a summary as its output.
Theory - Speech is the most frequent mode of communication, with the majority of the world's population using it to communicate. The basic function of a speech
recognition system is to convert spoken languages to text. Speech recognition systems are used in a variety of ways in real life. Apple SIRI, for example, recognizes speech and converts it into text. As images and videos, sound is also an Analog signal that humans perceive through sensory organs.This information must be stored as digital signals and evaluated by software before it can be consumed by machines. The following two processes are involved in the analog-to-digital conversion:
1. Sampling: It is a procedure used to convert a time-varying (changing with time) signal s(t) to a discrete progression of real numbers x(n). Sampling period (Ts) is a term that defines the interval between two successive discrete samples.
2. Quantization: This is the process of replacing every real number generated by sampling with an approximation to obtain a finite precision (defined within a
range of bits).
About Text to Speech (TTS) Converters: Text to voice converters use a variety of algorithms to turn text into speech. They may be used for a variety of purposes and are especially beneficial when you have a sore throat. Normally, python Text to Speech converters can only be used through CLI if you have an active internet connection, but for this project, we'll construct a GUI python Text to Speech converter that you can use from your computer even if you don't have an online connection. 
About Speech to Text (STT) Converters: Speech to text converters do exactly what their name implies: they convert spoken words into text. They're very beneficial when you need to produce a large document quickly without typing before forgetting what you're supposed to write. The APIs for converting python voice to text employ online or offline engines and require an active internet connection. We'll utilise an online engine, but we'll also show you how to use an offline engine if that's more convenient for you
How does Speech Recognition work?
With the help of the “Speech Recognition” API and “PyAudio'' library. Speech Recognition API supports several API’s we have used Google speech recognition API. The Google speech recognition API offers a simple way to convert speech to text, but it requires an internet connection to function
Converting an audio file that we have taken from the user into text
1. Import Speech recognition library.
2. Initialising recognizer class in order to recognize the speech. We are
using google speech recognition.
Converting different audio languages
1. For example, if we want to read a Gujarati/Hindi/Marathi language audio
file, then we need to add a language option in the recogonize_google.
Remaining code remains the same.
Talking in a different language
1. Again, we need to add the required language option in the recognize_google(). GUI for TTS and STT
We started by making a primary GUI window. The Label and Button widgets, for example, show static text on the window that the user cannot choose or change in any manner. In the form of parameters, the.configure() function is used to specify particular characteristics of the window. We'll generate and position all of the window's components now that it's been established. The Label widget class is used to show static text on the window that the user cannot select or alter in any manner. To make a Label widget, we set the following attributes: The window with which the master attribute is linked is referred to as the master attribute. The text property defines the text that will appear on the page
Conclusion:
Speech summarisation is a fast-growing field of research that has the potential to contribute to many application domains and tasks. At present however, the evidence for their effectiveness remains limited. The wide variety of approaches, tasks and study designs limits our ability to genuinely compare the effectiveness of much of the published research. For this reason, future research should report in a more standardised way, and use standard public corpora to assist with performance comparisons.
